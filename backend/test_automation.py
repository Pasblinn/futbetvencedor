#!/usr/bin/env python3
"""
üß™ TESTE DE AUTOMA√á√ÉO END-TO-END
Valida que todo o pipeline autom√°tico est√° funcionando

Testa:
1. ‚úÖ Scheduler pode iniciar
2. ‚úÖ Jobs est√£o registrados corretamente
3. ‚úÖ AI Agent est√° dispon√≠vel (Ollama)
4. ‚úÖ ML Retraining pode executar
5. ‚úÖ AI Agent batch pode processar predictions
"""

import sys
import os
from pathlib import Path

# Adicionar backend ao path
backend_path = Path(__file__).parent
sys.path.insert(0, str(backend_path))

import asyncio
from datetime import datetime
from sqlalchemy.orm import Session

from app.core.database import SessionLocal, engine
from app.models.prediction import Prediction
from app.services.data_scheduler import DataScheduler
from app.services.ai_agent_service import AIAgentService
from app.services.ai_agent_batch import AIAgentBatchService, analyze_unanalyzed_predictions
from app.services.automated_ml_retraining import AutomatedMLRetraining


def print_header(title: str):
    """Imprime cabe√ßalho formatado"""
    print("\n" + "=" * 80)
    print(f"  {title}")
    print("=" * 80 + "\n")


def test_scheduler_initialization(db: Session):
    """Teste 1: Scheduler pode iniciar e registrar jobs"""
    print_header("TESTE 1: Inicializa√ß√£o do Scheduler")

    try:
        scheduler = DataScheduler(db)

        print("üöÄ Iniciando scheduler...")
        scheduler.start()

        # Verificar status
        status = scheduler.get_status()

        print(f"‚úÖ Status: {status['status']}")
        print(f"üìã Jobs registrados: {len(status['jobs'])}")

        # Listar jobs
        print("\nüìä Jobs configurados:")
        for job in status['jobs']:
            next_run = job.get('next_run', 'N/A')
            print(f"  ‚Ä¢ {job['name']} (id: {job['id']})")
            print(f"    Pr√≥xima execu√ß√£o: {next_run}")

        # Parar scheduler
        scheduler.stop()
        print("\n‚úÖ Teste 1 PASSOU - Scheduler funciona corretamente")

        return True

    except Exception as e:
        print(f"\n‚ùå Teste 1 FALHOU: {e}")
        import traceback
        traceback.print_exc()
        return False


def test_ai_agent_availability():
    """Teste 2: AI Agent est√° dispon√≠vel (Ollama conectado)"""
    print_header("TESTE 2: Disponibilidade do AI Agent")

    try:
        ai_agent = AIAgentService(model="llama3.1:8b")

        if ai_agent.is_available():
            print("‚úÖ AI Agent dispon√≠vel")
            print(f"   Modelo: {ai_agent.model}")
            print("   Ollama est√° rodando corretamente")

            return True
        else:
            print("‚ùå AI Agent N√ÉO dispon√≠vel")
            print("üîß Certifique-se que Ollama est√° rodando:")
            print("   1. ollama serve")
            print("   2. ollama pull llama3.1:8b")

            return False

    except Exception as e:
        print(f"\n‚ùå Teste 2 FALHOU: {e}")
        import traceback
        traceback.print_exc()
        return False


def test_ml_retraining(db: Session):
    """Teste 3: ML Retraining pode executar"""
    print_header("TESTE 3: ML Retraining")

    try:
        # Verificar quantos resultados temos
        results_count = db.query(Prediction).filter(
            Prediction.is_winner.isnot(None)
        ).count()

        print(f"üìä Resultados dispon√≠veis: {results_count}")

        if results_count < 20:
            print("‚ö†Ô∏è Poucos resultados para treinar (m√≠nimo: 20)")
            print("   Teste ser√° pulado (aguardando mais dados)")
            return True

        # Tentar retreinar um modelo
        print("\nü§ñ Testando retraining do modelo 1x2_classifier...")

        retraining_service = AutomatedMLRetraining()

        trigger = {
            'trigger_type': 'manual',
            'threshold_value': 0.0,
            'current_value': 0.0,
            'reason': 'Test automation'
        }

        result = retraining_service.retrain_model('1x2_classifier', trigger)

        if result and result.success:
            print(f"‚úÖ Retraining executado com sucesso")
            print(f"   Samples: {result.training_samples}")
            print(f"   Accuracy antiga: {result.old_accuracy:.2%}")
            print(f"   Accuracy nova: {result.new_accuracy:.2%}")
            print(f"   Melhoria: {result.improvement*100:+.1f}%")

            return True
        else:
            print("‚ö†Ô∏è Retraining n√£o melhorou performance (esperado em alguns casos)")
            return True

    except Exception as e:
        print(f"\n‚ùå Teste 3 FALHOU: {e}")
        import traceback
        traceback.print_exc()
        return False


async def test_ai_agent_batch(db: Session):
    """Teste 4: AI Agent batch pode processar predictions"""
    print_header("TESTE 4: AI Agent Batch Processing")

    try:
        # Verificar quantas predictions pendentes temos
        pending_count = db.query(Prediction).filter(
            Prediction.ai_analyzed == False
        ).count()

        print(f"üìä Predictions pendentes: {pending_count}")

        if pending_count == 0:
            print("‚ÑπÔ∏è Nenhuma prediction pendente para processar")
            print("   Teste ser√° pulado (todas predictions j√° foram analisadas)")
            return True

        # Testar processamento batch
        print(f"\nüß† Processando at√© 10 predictions...")

        result = await analyze_unanalyzed_predictions(limit=10)

        if result.get('success'):
            stats = result.get('stats', {})
            print(f"‚úÖ Batch processing executado com sucesso")
            print(f"   Processadas: {stats.get('processed', 0)}")
            print(f"   Sucesso: {stats.get('success', 0)}")
            print(f"   Falhas: {stats.get('failed', 0)}")
            print(f"   Puladas: {stats.get('skipped', 0)}")

            return True
        else:
            error = result.get('error', 'Unknown')
            print(f"‚ùå Batch processing falhou: {error}")
            return False

    except Exception as e:
        print(f"\n‚ùå Teste 4 FALHOU: {e}")
        import traceback
        traceback.print_exc()
        return False


def print_summary(results: dict):
    """Imprime resumo dos testes"""
    print_header("RESUMO DOS TESTES")

    total = len(results)
    passed = sum(1 for r in results.values() if r)
    failed = total - passed

    for test_name, passed_test in results.items():
        status = "‚úÖ PASSOU" if passed_test else "‚ùå FALHOU"
        print(f"{status} - {test_name}")

    print(f"\nüìä Total: {passed}/{total} testes passaram")

    if failed == 0:
        print("\nüéâ TODOS OS TESTES PASSARAM! Automa√ß√£o est√° funcionando corretamente.")
    else:
        print(f"\n‚ö†Ô∏è {failed} teste(s) falharam. Verifique os erros acima.")


async def main():
    """Executa todos os testes"""
    print_header("üß™ TESTE DE AUTOMA√á√ÉO END-TO-END")
    print("Timestamp:", datetime.now().isoformat())

    # Criar sess√£o do banco
    db = SessionLocal()

    results = {}

    try:
        # Teste 1: Scheduler
        results["Scheduler Initialization"] = test_scheduler_initialization(db)

        # Teste 2: AI Agent
        results["AI Agent Availability"] = test_ai_agent_availability()

        # Teste 3: ML Retraining
        results["ML Retraining"] = test_ml_retraining(db)

        # Teste 4: AI Agent Batch (apenas se AI Agent dispon√≠vel)
        if results["AI Agent Availability"]:
            results["AI Agent Batch"] = await test_ai_agent_batch(db)
        else:
            print("\n‚ö†Ô∏è Pulando teste AI Agent Batch (AI Agent n√£o dispon√≠vel)")
            results["AI Agent Batch"] = False

    finally:
        db.close()

    # Resumo
    print_summary(results)

    # Exit code
    if all(results.values()):
        sys.exit(0)
    else:
        sys.exit(1)


if __name__ == "__main__":
    asyncio.run(main())
