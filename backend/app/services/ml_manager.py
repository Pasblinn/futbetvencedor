"""
ðŸŽ¯ ML MANAGER - Gerenciador Principal do Sistema de Machine Learning
Coordena treinamento, prediÃ§Ãµes e integraÃ§Ã£o com o motor matemÃ¡tico
"""

import asyncio
from typing import Dict, List, Optional
from datetime import datetime, timedelta
from pathlib import Path
import json

from app.services.ml_prediction_engine import MLPredictionEngine
from app.services.ml_training_service import MLTrainingService
from app.services.real_prediction_engine import RealPredictionEngine
from app.core.config import settings

class MLManager:
    """
    ðŸŽ¯ Gerenciador central do sistema de ML
    Coordena todas as operaÃ§Ãµes de machine learning
    """

    def __init__(self):
        self.ml_engine = MLPredictionEngine()
        self.training_service = MLTrainingService()
        self.real_engine = RealPredictionEngine()

        # Status do sistema
        self.system_status = {
            'models_trained': False,
            'last_training_date': None,
            'models_available': [],
            'training_in_progress': False
        }

        # ConfiguraÃ§Ãµes
        self.config = {
            'auto_retrain_days': 30,  # Retreinar a cada 30 dias
            'min_prediction_confidence': 0.6,
            'ensemble_weights': {
                'ml_weight': 0.6,
                'mathematical_weight': 0.4
            }
        }

    async def initialize_ml_system(self) -> Dict:
        """
        ðŸš€ Inicializar sistema de ML completo
        """
        print("ðŸš€ INICIALIZANDO SISTEMA DE MACHINE LEARNING")
        print("=" * 50)

        initialization_result = {
            'status': 'INITIALIZING',
            'steps': [],
            'errors': [],
            'start_time': datetime.now().isoformat()
        }

        try:
            # 1. Verificar se modelos existem
            print("ðŸ” Verificando modelos existentes...")
            models_check = await self._check_existing_models()
            initialization_result['steps'].append({
                'step': 'check_models',
                'result': models_check,
                'timestamp': datetime.now().isoformat()
            })

            # 2. Se nÃ£o existem modelos, fazer treinamento inicial
            if not models_check['models_exist']:
                print("ðŸŽ“ Modelos nÃ£o encontrados. Iniciando treinamento inicial...")
                training_result = await self.training_service.run_full_training_pipeline()
                initialization_result['steps'].append({
                    'step': 'initial_training',
                    'result': training_result,
                    'timestamp': datetime.now().isoformat()
                })

                if training_result.get('status') != 'SUCCESS':
                    initialization_result['errors'].extend(training_result.get('errors', []))
                    initialization_result['status'] = 'FAILED'
                    return initialization_result

            # 3. Carregar modelos
            print("ðŸ“¥ Carregando modelos...")
            load_result = await self._load_models()
            initialization_result['steps'].append({
                'step': 'load_models',
                'result': load_result,
                'timestamp': datetime.now().isoformat()
            })

            # 4. Teste de funcionamento
            print("ðŸ§ª Testando sistema...")
            test_result = await self._test_ml_system()
            initialization_result['steps'].append({
                'step': 'system_test',
                'result': test_result,
                'timestamp': datetime.now().isoformat()
            })

            # 5. Atualizar status
            await self._update_system_status()

            initialization_result['status'] = 'SUCCESS'
            initialization_result['end_time'] = datetime.now().isoformat()

            print("âœ… Sistema de ML inicializado com sucesso!")
            return initialization_result

        except Exception as e:
            initialization_result['errors'].append(str(e))
            initialization_result['status'] = 'FAILED'
            initialization_result['end_time'] = datetime.now().isoformat()
            print(f"âŒ Erro na inicializaÃ§Ã£o: {e}")
            return initialization_result

    async def generate_enhanced_prediction(self, home_team_id: str, away_team_id: str, match_date: datetime = None) -> Dict:
        """
        ðŸ”® Gerar prediÃ§Ã£o avanÃ§ada combinando ML + MatemÃ¡tica
        """
        if match_date is None:
            match_date = datetime.now()

        prediction_result = {
            'match_info': {
                'home_team_id': home_team_id,
                'away_team_id': away_team_id,
                'match_date': match_date.isoformat(),
                'prediction_timestamp': datetime.now().isoformat()
            },
            'predictions': {},
            'confidence': {},
            'recommendations': [],
            'system_status': self.system_status.copy()
        }

        try:
            print(f"ðŸ”® Gerando prediÃ§Ã£o avanÃ§ada: {home_team_id} vs {away_team_id}")

            # 1. Verificar se modelos estÃ£o disponÃ­veis
            if not self.system_status['models_trained']:
                print("âš ï¸ Modelos ML nÃ£o disponÃ­veis, usando apenas motor matemÃ¡tico...")
                math_only = await self.real_engine.generate_real_prediction(
                    f"{home_team_id}_vs_{away_team_id}",
                    home_team_id,
                    away_team_id,
                    match_date
                )
                prediction_result['predictions']['mathematical_only'] = math_only
                prediction_result['confidence']['overall'] = 'MEDIUM'
                prediction_result['recommendations'].append("Considere treinar modelos ML para prediÃ§Ãµes mais precisas")
                return prediction_result

            # 2. PrediÃ§Ã£o ML
            print("ðŸ¤– Gerando prediÃ§Ã£o ML...")
            ml_prediction = await self.ml_engine.predict_with_ml(home_team_id, away_team_id, match_date)

            # 3. PrediÃ§Ã£o MatemÃ¡tica
            print("ðŸ“Š Gerando prediÃ§Ã£o matemÃ¡tica...")
            math_prediction = await self.real_engine.generate_real_prediction(
                f"{home_team_id}_vs_{away_team_id}",
                home_team_id,
                away_team_id,
                match_date
            )

            # 4. Ensemble Inteligente
            print("ðŸŽ¯ Combinando prediÃ§Ãµes em ensemble...")
            ensemble_prediction = await self._create_intelligent_ensemble(ml_prediction, math_prediction)

            # 5. AnÃ¡lise de ConfianÃ§a
            confidence_analysis = await self._analyze_prediction_confidence(ml_prediction, math_prediction, ensemble_prediction)

            # 6. RecomendaÃ§Ãµes
            recommendations = await self._generate_prediction_recommendations(ensemble_prediction, confidence_analysis)

            # Estruturar resultado final
            prediction_result.update({
                'predictions': {
                    'ml_prediction': ml_prediction,
                    'mathematical_prediction': math_prediction,
                    'ensemble_prediction': ensemble_prediction
                },
                'confidence': confidence_analysis,
                'recommendations': recommendations,
                'system_info': {
                    'ml_models_used': len(self.system_status.get('models_available', [])),
                    'ensemble_weights': self.config['ensemble_weights'],
                    'prediction_engine_version': '2.0_ML_Enhanced'
                }
            })

            print("âœ… PrediÃ§Ã£o avanÃ§ada gerada com sucesso!")
            return prediction_result

        except Exception as e:
            prediction_result['error'] = str(e)
            prediction_result['recommendations'].append(f"Erro na prediÃ§Ã£o: {str(e)}")
            print(f"âŒ Erro na prediÃ§Ã£o avanÃ§ada: {e}")
            return prediction_result

    async def _create_intelligent_ensemble(self, ml_pred: Dict, math_pred: Dict) -> Dict:
        """
        ðŸ§  Criar ensemble inteligente baseado na confianÃ§a de cada mÃ©todo
        """
        try:
            # Analisar qualidade das prediÃ§Ãµes
            ml_confidence = self._extract_ml_confidence(ml_pred)
            math_confidence = self._extract_math_confidence(math_pred)

            # Ajustar pesos dinamicamente
            if ml_confidence > 0.7 and math_confidence < 0.6:
                ml_weight = 0.75
                math_weight = 0.25
            elif math_confidence > 0.7 and ml_confidence < 0.6:
                ml_weight = 0.4
                math_weight = 0.6
            else:
                ml_weight = self.config['ensemble_weights']['ml_weight']
                math_weight = self.config['ensemble_weights']['mathematical_weight']

            # Combinar prediÃ§Ãµes
            ensemble = {}

            # Resultado 1X2
            if 'ml_predictions' in ml_pred and 'match_outcome' in math_pred:
                ml_result = ml_pred.get('ml_predictions', {}).get('result', {})
                math_result = math_pred.get('match_outcome', {})

                ensemble['match_outcome'] = {
                    'home_win_probability': (
                        ml_result.get('probabilities', {}).get('H', 0.33) * ml_weight +
                        math_result.get('home_win_probability', 0.33) * math_weight
                    ),
                    'draw_probability': (
                        ml_result.get('probabilities', {}).get('D', 0.33) * ml_weight +
                        math_result.get('draw_probability', 0.33) * math_weight
                    ),
                    'away_win_probability': (
                        ml_result.get('probabilities', {}).get('A', 0.33) * ml_weight +
                        math_result.get('away_win_probability', 0.33) * math_weight
                    )
                }

                # Determinar resultado mais provÃ¡vel
                probs = ensemble['match_outcome']
                max_prob = max(probs.values())
                if probs['home_win_probability'] == max_prob:
                    ensemble['match_outcome']['predicted_result'] = '1'
                elif probs['away_win_probability'] == max_prob:
                    ensemble['match_outcome']['predicted_result'] = '2'
                else:
                    ensemble['match_outcome']['predicted_result'] = 'X'

                ensemble['match_outcome']['confidence'] = max_prob

            # Gols
            if 'ml_predictions' in ml_pred and 'goals_prediction' in math_pred:
                ml_goals = ml_pred.get('ml_predictions', {}).get('goals', {}).get('predicted_total_goals', 2.5)
                math_goals = math_pred.get('goals_prediction', {}).get('expected_total_goals', 2.5)

                ensemble_goals = ml_goals * ml_weight + math_goals * math_weight

                ensemble['goals_prediction'] = {
                    'expected_total_goals': round(ensemble_goals, 2),
                    'over_2_5_probability': self._calculate_over_probability(ensemble_goals, 2.5),
                    'over_1_5_probability': self._calculate_over_probability(ensemble_goals, 1.5),
                    'over_3_5_probability': self._calculate_over_probability(ensemble_goals, 3.5)
                }

            # BTTS
            if 'btts_prediction' in math_pred:
                ensemble['btts_prediction'] = math_pred['btts_prediction']

            # Metadados do ensemble
            ensemble['ensemble_info'] = {
                'ml_weight_used': ml_weight,
                'math_weight_used': math_weight,
                'ml_confidence': ml_confidence,
                'math_confidence': math_confidence,
                'dynamic_weighting': True
            }

            return ensemble

        except Exception as e:
            print(f"âŒ Erro no ensemble: {e}")
            return math_pred  # Fallback para prediÃ§Ã£o matemÃ¡tica

    def _extract_ml_confidence(self, ml_pred: Dict) -> float:
        """Extrair nÃ­vel de confianÃ§a da prediÃ§Ã£o ML"""
        try:
            if 'ml_predictions' in ml_pred:
                result_probs = ml_pred['ml_predictions'].get('result', {}).get('probabilities', {})
                if result_probs:
                    return max(result_probs.values())
            return 0.5
        except:
            return 0.5

    def _extract_math_confidence(self, math_pred: Dict) -> float:
        """Extrair nÃ­vel de confianÃ§a da prediÃ§Ã£o matemÃ¡tica"""
        try:
            confidence_system = math_pred.get('confidence_system', {})
            return confidence_system.get('overall_confidence', 0.5)
        except:
            return 0.5

    def _calculate_over_probability(self, expected_goals: float, threshold: float) -> float:
        """Calcular probabilidade Over usando distribuiÃ§Ã£o de Poisson"""
        try:
            from scipy.stats import poisson
            return 1 - poisson.cdf(threshold, expected_goals)
        except:
            # Fallback simples
            return max(0, min(1, (expected_goals - threshold) / 2))

    async def _analyze_prediction_confidence(self, ml_pred: Dict, math_pred: Dict, ensemble_pred: Dict) -> Dict:
        """
        ðŸ“Š Analisar confianÃ§a das prediÃ§Ãµes
        """
        try:
            ml_conf = self._extract_ml_confidence(ml_pred)
            math_conf = self._extract_math_confidence(math_pred)
            ensemble_conf = max(ensemble_pred.get('match_outcome', {}).get('confidence', 0.5), 0.5)

            # Classificar confianÃ§a
            def classify_confidence(conf):
                if conf >= 0.7:
                    return 'HIGH'
                elif conf >= 0.55:
                    return 'MEDIUM'
                else:
                    return 'LOW'

            return {
                'ml_confidence': {
                    'score': round(ml_conf, 3),
                    'level': classify_confidence(ml_conf)
                },
                'mathematical_confidence': {
                    'score': round(math_conf, 3),
                    'level': classify_confidence(math_conf)
                },
                'ensemble_confidence': {
                    'score': round(ensemble_conf, 3),
                    'level': classify_confidence(ensemble_conf)
                },
                'overall': classify_confidence(max(ml_conf, math_conf, ensemble_conf)),
                'agreement': abs(ml_conf - math_conf) < 0.2  # Se diferenÃ§a < 20%
            }

        except Exception as e:
            return {
                'error': str(e),
                'overall': 'MEDIUM'
            }

    async def _generate_prediction_recommendations(self, ensemble_pred: Dict, confidence_analysis: Dict) -> List[str]:
        """
        ðŸ’¡ Gerar recomendaÃ§Ãµes baseadas na prediÃ§Ã£o
        """
        recommendations = []

        try:
            # ConfianÃ§a geral
            overall_confidence = confidence_analysis.get('overall', 'MEDIUM')

            if overall_confidence == 'HIGH':
                recommendations.append("âœ… Alta confianÃ§a - PrediÃ§Ã£o muito confiÃ¡vel")
            elif overall_confidence == 'MEDIUM':
                recommendations.append("âš ï¸ ConfianÃ§a moderada - Considere fatores adicionais")
            else:
                recommendations.append("âŒ Baixa confianÃ§a - Use com cautela")

            # AnÃ¡lise do resultado
            match_outcome = ensemble_pred.get('match_outcome', {})
            predicted_result = match_outcome.get('predicted_result', '')
            confidence = match_outcome.get('confidence', 0)

            if confidence > 0.6:
                result_map = {'1': 'VitÃ³ria da Casa', 'X': 'Empate', '2': 'VitÃ³ria Visitante'}
                recommendations.append(f"ðŸŽ¯ Resultado mais provÃ¡vel: {result_map.get(predicted_result, 'Indefinido')}")

            # AnÃ¡lise de gols
            goals_pred = ensemble_pred.get('goals_prediction', {})
            expected_goals = goals_pred.get('expected_total_goals', 0)

            if expected_goals > 3.0:
                recommendations.append("âš½ Jogo com tendÃªncia a muitos gols (Over 2.5)")
            elif expected_goals < 2.0:
                recommendations.append("ðŸ”’ Jogo com tendÃªncia a poucos gols (Under 2.5)")

            # AcordÃ¢ncia entre mÃ©todos
            if confidence_analysis.get('agreement', False):
                recommendations.append("ðŸ¤ ML e AnÃ¡lise MatemÃ¡tica concordam - Maior confiabilidade")
            else:
                recommendations.append("âš–ï¸ DivergÃªncia entre mÃ©todos - AnÃ¡lise adicional recomendada")

        except Exception as e:
            recommendations.append(f"âš ï¸ Erro na anÃ¡lise: {str(e)}")

        return recommendations

    async def _check_existing_models(self) -> Dict:
        """Verificar se modelos jÃ¡ existem"""
        try:
            models_file = Path("app/ml/models/trained_models.joblib")
            return {
                'models_exist': models_file.exists(),
                'models_path': str(models_file),
                'file_size': models_file.stat().st_size if models_file.exists() else 0
            }
        except Exception as e:
            return {'models_exist': False, 'error': str(e)}

    async def _load_models(self) -> Dict:
        """Carregar modelos existentes"""
        try:
            models_data = await self.ml_engine._load_models()
            if models_data:
                self.system_status['models_trained'] = True
                self.system_status['models_available'] = list(models_data.get('result_models', {}).keys())
                return {'status': 'SUCCESS', 'models_loaded': len(self.system_status['models_available'])}
            return {'status': 'FAILED', 'error': 'No models found'}
        except Exception as e:
            return {'status': 'FAILED', 'error': str(e)}

    async def _test_ml_system(self) -> Dict:
        """Testar funcionamento do sistema ML"""
        try:
            # Teste simples com IDs fictÃ­cios
            test_result = await self.ml_engine.predict_with_ml("1", "2", datetime.now())
            return {
                'test_passed': 'error' not in test_result,
                'test_result': 'SUCCESS' if 'error' not in test_result else test_result.get('error')
            }
        except Exception as e:
            return {'test_passed': False, 'error': str(e)}

    async def _update_system_status(self):
        """Atualizar status do sistema"""
        self.system_status['last_training_date'] = datetime.now().isoformat()

    async def check_retrain_needed(self) -> bool:
        """Verificar se Ã© necessÃ¡rio retreinar"""
        if not self.system_status['last_training_date']:
            return True

        last_train = datetime.fromisoformat(self.system_status['last_training_date'])
        days_since_train = (datetime.now() - last_train).days

        return days_since_train >= self.config['auto_retrain_days']

    async def auto_retrain_if_needed(self) -> Dict:
        """Retreinar automaticamente se necessÃ¡rio"""
        if await self.check_retrain_needed():
            print("ðŸ”„ Retreinamento automÃ¡tico iniciado...")
            return await self.training_service.quick_retrain()
        else:
            return {'status': 'NO_RETRAIN_NEEDED'}

# InstÃ¢ncia global do manager
ml_manager = MLManager()